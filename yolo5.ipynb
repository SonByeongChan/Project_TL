{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba77305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_bbox(size, box):\n",
    "    dw, dh = 1. / size[0], 1. / size[1]\n",
    "    x_center = ((box[0] + box[1]) / 2.0 - 1) * dw\n",
    "    y_center = ((box[2] + box[3]) / 2.0 - 1) * dh\n",
    "    width = (box[1] - box[0]) * dw\n",
    "    height = (box[3] - box[2]) * dh\n",
    "    return (x_center, y_center, width, height)\n",
    "\n",
    "def xml_to_yolo(xml_folder, save_folder, classes):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
    "\n",
    "    for xml_file in xml_files:\n",
    "        tree = ET.parse(os.path.join(xml_folder, xml_file))\n",
    "        root = tree.getroot()\n",
    "        size = root.find('size')\n",
    "        w, h = int(size.find('width').text), int(size.find('height').text)\n",
    "        txt_path = os.path.join(save_folder, xml_file.replace('.xml', '.txt'))\n",
    "\n",
    "        with open(txt_path, 'w') as f:\n",
    "            for obj in root.iter('object'):\n",
    "                cls = obj.find('name').text\n",
    "                if cls not in classes:\n",
    "                    continue\n",
    "                cls_id = classes.index(cls)\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text),\n",
    "                     float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "                bb = convert_bbox((w, h), b)\n",
    "                f.write(f\"{cls_id} {' '.join(map(str, bb))}\\n\")\n",
    "\n",
    "    print(f\"[XML → YOLO] 변환 완료: {len(xml_files)}개 파일\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ec8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XML → YOLO] 변환 완료: 2529개 파일\n",
      "[XML → YOLO] 변환 완료: 680개 파일\n"
     ]
    }
   ],
   "source": [
    "classes = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "xml_to_yolo('./project_root/train_annotations', './project_root/labels/train', classes)\n",
    "xml_to_yolo('.//project_root/val_annotations', './project_root/labels/val', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0793d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b95c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml 파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# data.yaml 내용 문자열로 생성 (경로는 필요에 맞게 수정하세요)\n",
    "data_yaml_content = \"\"\"\n",
    "train: ./train_images\n",
    "val: ./val_images\n",
    "\n",
    "nc: 6\n",
    "names: ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\"\"\"\n",
    "\n",
    "# data.yaml 파일로 저장\n",
    "with open('data.yaml', 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(\"data.yaml 파일 생성 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06eeb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.112  Python-3.9.21 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-1155G7 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=my_project, name=train_from_scratch, exist_ok=True, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=my_project\\train_from_scratch\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv8n summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1252.5186.7 MB/s, size: 1079.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\train\\labels... 2529 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2529/2529 [00:05<00:00, 475.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 26.62.8 MB/s, size: 1240.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:17<00:00, 39.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to my_project\\train_from_scratch\\labels.jpg... \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 모델 구조만 불러오기 (가중치 랜덤 초기화)\n",
    "model = YOLO('yolov8n.yaml')\n",
    "\n",
    "# 학습 실행 (epoch, batch size 등은 환경에 맞게 조절)\n",
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    project='my_project',\n",
    "    name='train_from_scratch',\n",
    "    exist_ok=True,\n",
    "    pretrained=False  # 사전학습 가중치 사용 안함\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 실행 (best.pt 가중치 기준)\n",
    "val_results = model.val()\n",
    "\n",
    "# val_results는 ultralytics 내부 결과 객체입니다.\n",
    "print(\"\\n검증 결과 요약:\")\n",
    "print(val_results.metrics)  # precision, recall, mAP 등 주요 지표 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼돈행렬 가져오기 (val_results.confusion_matrix)\n",
    "cm = val_results.confusion_matrix\n",
    "\n",
    "# 클래스 이름\n",
    "class_names = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ultralytics val 결과에서 IOU 히스토그램 그리기\n",
    "ious = val_results.ious  # 각 예측 박스별 IOU 배열\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(ious, bins=50, alpha=0.75, color='g')\n",
    "plt.title('Distribution of IOU values')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d67a1",
   "metadata": {},
   "source": [
    "[쿠다]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4019ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING torchvision==0.20 is incompatible with torch==2.4.\n",
      "Run 'pip install torchvision==0.19' to fix torchvision or 'pip install -U torch torchvision' to update both.\n",
      "For a full compatibility table see https://github.com/pytorch/vision#installation\n",
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\user\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "CUDA 사용 가능 여부: False\n",
      "사용 디바이스: CPU 사용 중\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"사용 디바이스: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU 사용 중'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eecdcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov5n.yaml')  # 모델 구조만 불러오기 (가중치 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4d0b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105  Python-3.9.21 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100 80GB PCIe, 81454MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5n.yaml, data=data.yaml, epochs=10, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=my_project, name=train_from_scratch_cuda, exist_ok=True, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=my_project\\train_from_scratch_cuda\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,634 parameters, 2,509,618 gradients\n",
      "\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\train\\labels.cache... 2529 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2529/2529 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to my_project\\train_from_scratch_cuda\\labels.jpg... \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=10,\n",
    "    batch=8,\n",
    "    imgsz=640,\n",
    "    pretrained=False,   # 가중치 없이 처음부터 학습\n",
    "    device=0,           # GPU 0번 사용 (CUDA)\n",
    "    project='my_project',\n",
    "    name='train_from_scratch_cuda',\n",
    "    exist_ok=True,\n",
    "    plots=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.val()\n",
    "\n",
    "print(\"평가지표:\")\n",
    "print(results.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = results.confusion_matrix\n",
    "class_names = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('예측 클래스')\n",
    "plt.ylabel('실제 클래스')\n",
    "plt.title('혼돈행렬')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = results.ious\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(ious, bins=50, color='green', alpha=0.7)\n",
    "plt.title('IOU 분포')\n",
    "plt.xlabel('IOU 값')\n",
    "plt.ylabel('빈도수')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c81d6b",
   "metadata": {},
   "source": [
    "내가 하고자 하는 프로젝트는 공항검색대의 x-ray 사진을 가지고 위험물을 파악하여 이를 객체로 인식해서 바운딩 박스가 나오게 끔 하는거야 \n",
    "여기서 내가 준비한 클래스의 이름은 ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner' , 'ZippoOil'] 이야\n",
    "그리고 훈련 데이터 셋이 저장된 폴더와 이 데이터에 대하여 정보가 저장되어 있는 xml 데이터 폴더가 있고\n",
    "검증용 데이터 셋이 저장되어 있는 폴더와 이 데이터에 대하여 정보가 저장되어 있는 xml 데이터 폴더가 있어 \n",
    "이를 바탕으로 파이토치의 YOLO5를 사용하여 모델을 만들고자 해 이때에 사용되는 에폭의 수는 5이고 평가지수로는 IoU와 recall, precision, summary(F1, 혼돈행렬)을 활용하고자 해 이때에 하나의 에폭마다 모델을 저장하는데 정확도도 모델 이름에 들어 갔으면 좋겠어 \n",
    "내가 할 것은 cuda 12.4를 쓸건데 위의 내용을 바탕으로 코드를 짜주고 어떠헌 가상환경을 사용하여야 하는지 알려주라 \n",
    "발표가 10시간밖에 남지 않았어 제발 도와줘 ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734ed24",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'runs/detect/exp/labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# 예측 결과 디렉토리\u001b[39;00m\n\u001b[0;32m     67\u001b[0m pred_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/detect/exp/labels\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# YOLOv5의 예측 결과가 저장되는 디렉토리\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mread_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 정확도 계산\u001b[39;00m\n\u001b[0;32m     71\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m, in \u001b[0;36mread_predictions\u001b[1;34m(pred_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# 검증 데이터셋의 실제 레이블을 가져오는 방법 (예: 파일에서 읽기)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 여기서는 예시로 y_true를 수동으로 정의합니다.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# 실제로는 검증 데이터셋의 레이블을 읽어와야 합니다.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 예측 결과 파일 읽기\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pred_dir, filename), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'runs/detect/exp/labels'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0c1e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "It looks like there is no internet connection and the repo could not be found in the cache (C:\\Users\\user/.cache\\torch\\hub)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1354\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:1418\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1418\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\http\\client.py:922\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\socket.py:799\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    798\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    800\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\socket.py:930\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    929\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 930\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    931\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\torch\\hub.py:152\u001b[0m, in \u001b[0;36m_parse_repo_info\u001b[1;34m(github)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_owner\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tree/main/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    153\u001b[0m         ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:1397\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\urllib\\request.py:1357\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1358\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# YOLOv5n 모델 로드\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43multralytics/yolov5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolov5n\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\torch\\hub.py:567\u001b[0m, in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown source: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Allowed values: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 567\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m \u001b[43m_get_cache_or_reload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m model \u001b[38;5;241m=\u001b[39m _load_local(repo_or_dir, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\torch\\hub.py:208\u001b[0m, in \u001b[0;36m_get_cache_or_reload\u001b[1;34m(github, force_reload, trust_repo, calling_fn, verbose, skip_validation)\u001b[0m\n\u001b[0;32m    206\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(hub_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Parse github repo information\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m repo_owner, repo_name, ref \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_repo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgithub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Github allows branch name with slash '/',\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# this causes confusion with path on both Linux and Windows.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Backslash is not allowed in Github branch name so no need to\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# to worry about it.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m normalized_br \u001b[38;5;241m=\u001b[39m ref\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\torch\\hub.py:166\u001b[0m, in \u001b[0;36m_parse_repo_info\u001b[1;34m(github)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like there is no internet connection and the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo could not be found in the cache (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_dir()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repo_owner, repo_name, ref\n",
      "\u001b[1;31mRuntimeError\u001b[0m: It looks like there is no internet connection and the repo could not be found in the cache (C:\\Users\\user/.cache\\torch\\hub)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# YOLOv5n 모델 로드\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61511678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 16, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): SPPF(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (16): Concat()\n",
       "    (17): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (19): Concat()\n",
       "    (20): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (22): Concat()\n",
       "    (23): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (24): Detect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(64, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "# 모델의 모든 레이어에 가중치 초기화 적용\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6918cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (16): Concat()\n",
      "    (17): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (19): Concat()\n",
      "    (20): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (22): Concat()\n",
      "    (23): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): Detect(\n",
      "      (m): ModuleList(\n",
      "        (0): Conv2d(64, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99879cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841509ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1 CPU (Intel Xeon Gold 6346 3.10GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5n.yaml, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,634 parameters, 2,509,618 gradients, 7.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2189.6597.7 MB/s, size: 1079.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\train\\labels.cache... 2529 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2529/2529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2374.1269.0 MB/s, size: 1240.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      4.155      7.384       3.77          2        640: 100%|██████████| 159/159 [05:15<00:00,  1.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:38<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682    0.00177      0.221    0.00992    0.00246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G      2.992      4.486      2.678          2        640: 100%|██████████| 159/159 [05:02<00:00,  1.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:35<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682     0.0106      0.254     0.0415     0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G      2.671      3.324      2.323          2        640: 100%|██████████| 159/159 [05:00<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:31<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.462      0.298      0.237      0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G      2.455      2.734      2.145          4        640: 100%|██████████| 159/159 [04:56<00:00,  1.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:30<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.357       0.43      0.371       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G      2.261      2.383      1.998          4        640: 100%|██████████| 159/159 [05:00<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:32<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.591      0.499      0.543      0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.470 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1 CPU (Intel Xeon Gold 6346 3.10GHz)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,114 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 22/22 [00:29<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.581      0.499      0.543      0.287\n",
      "           Firecracker         98         98      0.749      0.133      0.259      0.129\n",
      "                Hammer         78         78       0.79      0.385      0.586      0.213\n",
      "          NailClippers         60         60        0.7      0.584      0.674      0.338\n",
      "               Spanner        414        416      0.535      0.892      0.827      0.432\n",
      "               Thinner         15         15       0.43        0.6      0.533      0.369\n",
      "              ZippoOil         15         15      0.283        0.4      0.377      0.239\n",
      "Speed: 0.6ms preprocess, 11.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1 CPU (Intel Xeon Gold 6346 3.10GHz)\n",
      "YOLOv5n summary (fused): 84 layers, 2,504,114 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2308.8288.0 MB/s, size: 1110.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:28<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.581      0.499      0.543      0.287\n",
      "           Firecracker         98         98      0.749      0.133      0.259      0.129\n",
      "                Hammer         78         78       0.79      0.385      0.586      0.213\n",
      "          NailClippers         60         60        0.7      0.584      0.674      0.338\n",
      "               Spanner        414        416      0.535      0.892      0.827      0.432\n",
      "               Thinner         15         15       0.43        0.6      0.533      0.369\n",
      "              ZippoOil         15         15      0.283        0.4      0.377      0.239\n",
      "Speed: 0.5ms preprocess, 10.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train22\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DetMetrics' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# IoU, Recall, Precision, F1 Score, Confusion Matrix\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m iou \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIoU\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     43\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     44\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DetMetrics' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO  # YOLOv5 모델을 가져옵니다.\n",
    "\n",
    "# 설정\n",
    "data_dir = r'F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset'  # 데이터셋 경로\n",
    "train_images_dir = os.path.join(data_dir, 'train')  # 훈련 이미지 경로\n",
    "val_images_dir = os.path.join(data_dir, 'val')  # 검증 이미지 경로\n",
    "\n",
    "# 클래스 이름\n",
    "class_names = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\n",
    "# 데이터셋 설정\n",
    "data_yaml = {\n",
    "    'train': str(Path(train_images_dir)),\n",
    "    'val': str(Path(val_images_dir)),\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "# YAML 파일로 저장\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "# YOLOv5 모델 로드\n",
    "model = YOLO(\"yolov5n.yaml\")  # 모델을 YAML 파일로부터 로드합니다.\n",
    "\n",
    "# 훈련 설정\n",
    "epochs = 5\n",
    "device = 'cuda:0'\n",
    "print(device)\n",
    "\n",
    "# 모델 훈련\n",
    "results = model.train(data='data.yaml', epochs=epochs, imgsz=640, batch=16, device=device)\n",
    "\n",
    "# 평가\n",
    "metrics = model.val(data='data.yaml', imgsz=640)\n",
    "\n",
    "# IoU, Recall, Precision, F1 Score, Confusion Matrix\n",
    "iou = metrics['metrics']['IoU']\n",
    "recall = metrics['metrics']['recall']\n",
    "precision = metrics['metrics']['precision']\n",
    "f1 = metrics['metrics']['f1']\n",
    "confusion_matrix = metrics['metrics']['confusion_matrix']\n",
    "\n",
    "print(f'IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix}')\n",
    "\n",
    "print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "275d9d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1 CPU (Intel Xeon Gold 6346 3.10GHz)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1217.6187.0 MB/s, size: 1195.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:29<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.581      0.499      0.543      0.287\n",
      "           Firecracker         98         98      0.749      0.133      0.259      0.129\n",
      "                Hammer         78         78       0.79      0.385      0.586      0.213\n",
      "          NailClippers         60         60        0.7      0.584      0.674      0.338\n",
      "               Spanner        414        416      0.535      0.892      0.827      0.432\n",
      "               Thinner         15         15       0.43        0.6      0.533      0.369\n",
      "              ZippoOil         15         15      0.283        0.4      0.377      0.239\n",
      "Speed: 0.5ms preprocess, 11.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train23\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DetMetrics' object has no attribute 'iou'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# IoU, Recall, Precision, F1 Score, Confusion Matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m iou \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m  \u001b[38;5;66;03m# IoU 값\u001b[39;00m\n\u001b[0;32m      6\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mrecall  \u001b[38;5;66;03m# Recall 값\u001b[39;00m\n\u001b[0;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mprecision  \u001b[38;5;66;03m# Precision 값\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\ultralytics\\utils\\__init__.py:241\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'iou'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    "
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "metrics = model.val(data='data.yaml', imgsz=640)\n",
    "\n",
    "# IoU, Recall, Precision, F1 Score, Confusion Matrix\n",
    "iou = metrics.iou  # IoU 값\n",
    "recall = metrics.recall  # Recall 값\n",
    "precision = metrics.precision  # Precision 값\n",
    "f1 = metrics.f1  # F1 Score 값\n",
    "confusion_matrix = metrics.confusion_matrix  # 혼동 행렬\n",
    "\n",
    "print(f'IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e658264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1 CPU (Intel Xeon Gold 6346 3.10GHz)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1559.8269.5 MB/s, size: 959.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 43/43 [00:29<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        680        682      0.581      0.499      0.543      0.287\n",
      "           Firecracker         98         98      0.749      0.133      0.259      0.129\n",
      "                Hammer         78         78       0.79      0.385      0.586      0.213\n",
      "          NailClippers         60         60        0.7      0.584      0.674      0.338\n",
      "               Spanner        414        416      0.535      0.892      0.827      0.432\n",
      "               Thinner         15         15       0.43        0.6      0.533      0.369\n",
      "              ZippoOil         15         15      0.283        0.4      0.377      0.239\n",
      "Speed: 0.5ms preprocess, 11.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train25\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metric' object has no attribute 'precision'. See valid attributes below.\n\n    Class for computing evaluation metrics for YOLOv8 model.\n\n    Attributes:\n        p (list): Precision for each class. Shape: (nc,).\n        r (list): Recall for each class. Shape: (nc,).\n        f1 (list): F1 score for each class. Shape: (nc,).\n        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n        nc (int): Number of classes.\n\n    Methods:\n        ap50(): AP at IoU threshold of 0.5 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        ap(): AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        mp(): Mean precision of all classes. Returns: Float.\n        mr(): Mean recall of all classes. Returns: Float.\n        map50(): Mean AP at IoU threshold of 0.5 for all classes. Returns: Float.\n        map75(): Mean AP at IoU threshold of 0.75 for all classes. Returns: Float.\n        map(): Mean AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: Float.\n        mean_results(): Mean of results, returns mp, mr, map50, map.\n        class_result(i): Class-aware result, returns p[i], r[i], ap50[i], ap[i].\n        maps(): mAP of each class. Returns: Array of mAP scores, shape: (nc,).\n        fitness(): Model fitness as a weighted combination of metrics. Returns: Float.\n        update(results): Update metric attributes with new evaluation results.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Precision, Recall, mAP\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m  \u001b[38;5;66;03m# Precision 값\u001b[39;00m\n\u001b[0;32m      6\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mrecall  \u001b[38;5;66;03m# Recall 값\u001b[39;00m\n\u001b[0;32m      7\u001b[0m map_value \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap  \u001b[38;5;66;03m# mAP 값\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDT\\anaconda3\\envs\\yolov5-env\\lib\\site-packages\\ultralytics\\utils\\__init__.py:241\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Metric' object has no attribute 'precision'. See valid attributes below.\n\n    Class for computing evaluation metrics for YOLOv8 model.\n\n    Attributes:\n        p (list): Precision for each class. Shape: (nc,).\n        r (list): Recall for each class. Shape: (nc,).\n        f1 (list): F1 score for each class. Shape: (nc,).\n        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n        nc (int): Number of classes.\n\n    Methods:\n        ap50(): AP at IoU threshold of 0.5 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        ap(): AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        mp(): Mean precision of all classes. Returns: Float.\n        mr(): Mean recall of all classes. Returns: Float.\n        map50(): Mean AP at IoU threshold of 0.5 for all classes. Returns: Float.\n        map75(): Mean AP at IoU threshold of 0.75 for all classes. Returns: Float.\n        map(): Mean AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: Float.\n        mean_results(): Mean of results, returns mp, mr, map50, map.\n        class_result(i): Class-aware result, returns p[i], r[i], ap50[i], ap[i].\n        maps(): mAP of each class. Returns: Array of mAP scores, shape: (nc,).\n        fitness(): Model fitness as a weighted combination of metrics. Returns: Float.\n        update(results): Update metric attributes with new evaluation results.\n    "
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "metrics = model.val(data='data.yaml', imgsz=640)\n",
    "\n",
    "# Precision, Recall, mAP\n",
    "precision = metrics.box.precision  # Precision 값\n",
    "recall = metrics.box.recall  # Recall 값\n",
    "map_value = metrics.box.map  # mAP 값\n",
    "\n",
    "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, mAP: {map_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f3fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 준비\n",
    "data = {\n",
    "    'Precision': [0.749, 0.790, 0.700, 0.535, 0.430, 0.283],\n",
    "    'Recall': [0.133, 0.385, 0.584, 0.892, 0.600, 0.400],\n",
    "    'mAP50': [0.259, 0.586, 0.674, 0.827, 0.533, 0.377],\n",
    "    'mAP50-95': [0.129, 0.213, 0.338, 0.432, 0.369, 0.239]\n",
    "}\n",
    "classes = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\n",
    "df = pd.DataFrame(data, index=classes)\n",
    "\n",
    "# 히트맵 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df, annot=True, cmap='YlGnBu', fmt=\".3f\")\n",
    "plt.title(\"heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a80c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.113-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.8.0.dev20250419+cu128)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (0.22.0.dev20250420+cu128)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Downloading ultralytics-8.3.113-py3-none-any.whl (982 kB)\n",
      "   ---------------------------------------- 0.0/982.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 982.4/982.4 kB 15.3 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: opencv-python, ultralytics-thop, ultralytics\n",
      "Successfully installed opencv-python-4.11.0.86 ultralytics-8.3.113 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ad6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "New https://pypi.org/project/ultralytics/8.3.113 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.112  Python-3.8.20 torch-2.4.1+cpu CPU (Intel Core(TM) Ultra 9 285K)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5n.yaml, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train9\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,634 parameters, 2,509,618 gradients, 7.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3057.1618.1 MB/s, size: 1079.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\train\\labels.cache... 2529 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2529/2529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3303.5474.9 MB/s, size: 1240.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset\\val\\labels.cache... 680 images, 0 backgrounds, 0 corrupt: 100%|██████████| 680/680 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train9\\labels.jpg... \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO  # YOLOv5 모델을 가져옵니다.\n",
    "\n",
    "# 설정\n",
    "data_dir = r'F:\\AI_KDT7\\12.Transfer_learning\\mini\\dataset'  # 데이터셋 경로\n",
    "train_images_dir = os.path.join(data_dir, 'train')  # 훈련 이미지 경로\n",
    "val_images_dir = os.path.join(data_dir, 'val')  # 검증 이미지 경로\n",
    "\n",
    "# 클래스 이름\n",
    "class_names = ['Firecracker', 'Hammer', 'NailClippers', 'Spanner', 'Thinner', 'ZippoOil']\n",
    "\n",
    "# 데이터셋 설정\n",
    "data_yaml = {\n",
    "    'train': str(Path(train_images_dir)),\n",
    "    'val': str(Path(val_images_dir)),\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "# YAML 파일로 저장\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "# YOLOv5 모델 로드\n",
    "model = YOLO(\"yolov5n.yaml\")  # 모델을 YAML 파일로부터 로드합니다.\n",
    "\n",
    "# 훈련 설정\n",
    "epochs = 5\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 모든 가중치 고정 해제\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True  # 모든 가중치 학습 가능하도록 설정\n",
    "\n",
    "# 모델 훈련\n",
    "results = model.train(data='data.yaml', epochs=epochs, imgsz=640, batch=16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ec94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "metrics = model.val(data='data.yaml', imgsz=640)\n",
    "\n",
    "# IoU, Recall, Precision, F1 Score, Confusion Matrix\n",
    "iou = metrics['metrics']['IoU']\n",
    "recall = metrics['metrics']['recall']\n",
    "precision = metrics['metrics']['precision']\n",
    "f1 = metrics['metrics']['f1']\n",
    "confusion_matrix = metrics['metrics']['confusion_matrix']\n",
    "\n",
    "print(f'IoU: {iou:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix}')\n",
    "\n",
    "print('Training complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
